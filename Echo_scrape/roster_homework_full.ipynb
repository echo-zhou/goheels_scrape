{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "import scrapy\n",
    "\n",
    "\n",
    "base_url = \"http://goheels.com/roster.aspx?path=mbball\"\n",
    "\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\"}\n",
    "\n",
    "\n",
    "\n",
    "resp = requests.get(base_url,headers=headers)\n",
    "body_bytes = resp.content\n",
    "body_str = body_bytes.decode(\"utf-8\")\n",
    "sel = scrapy.Selector(text=body_str)\n",
    "table = sel.css('.sidearm-table-grid-template-1-breakdown-large')\n",
    "\n",
    "record_dict = {}  # map the name to its record, which is a nother dict\n",
    "personas = table.css('tbody:nth-child(3) tr')  # get all information\n",
    "for persona in personas:\n",
    "    info_record = {}  # create an empty dict in the record_dict\n",
    "    name_obj = persona.css('.sidearm-table-player-name')\n",
    "    name = name_obj.xpath('string()').extract()[0]  # get name in .name class\n",
    "    href = 'http://goheels.com' + name_obj.xpath('a/@href').extract()[0]  # get href in .name class\n",
    "\n",
    "    resppicture = requests.get(href, headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\"})\n",
    "    bodypicture_bytes = resppicture.content\n",
    "    body_str_pic = bodypicture_bytes.decode(\"utf-8\")\n",
    "    selpicture = scrapy.Selector(text=body_str_pic)\n",
    "\n",
    "    picture = selpicture.css('.sidearm-roster-player-image').xpath('img/@src').extract()[0]\n",
    "    bio = selpicture.css('#sidearm-roster-player-bio').xpath(\"string()\").extract()[0]\n",
    "\n",
    "    info_record[\"name\"] = name\n",
    "    info_record[\"href\"] = href\n",
    "    info_record[\"number\"] = persona.css(\"td:nth-child(1)\").xpath(\"string()\").extract()[0]\n",
    "    info_record[\"position\"] = persona.css(\"td:nth-child(3)\").xpath(\"string()\").extract()[0]\n",
    "    info_record[\"height\"] = persona.css(\"td:nth-child(4)\").xpath(\"string()\").extract()[0]\n",
    "    info_record[\"weight\"] = persona.css(\"td:nth-child(5)\").xpath(\"string()\").extract()[0]\n",
    "    info_record[\"class\"] = persona.css(\"td:nth-child(6)\").xpath(\"string()\").extract()[0]\n",
    "    info_record[\"hometown_highschool\"] = persona.css(\"td:nth-child(7)\").xpath(\"string()\").extract()[0]\n",
    "    info_record[\"picture\"] = 'http://goheels.com' + picture\n",
    "    \n",
    "    info_record[\"bio\"] = bio.replace(\"\\n\", \"\").replace(\"\\r\", \"\").strip()\n",
    "\n",
    "    record_dict[name] = info_record\n",
    "\n",
    "\n",
    "output_file = open('records.json', 'w+')  # create json file\n",
    "json.dump(record_dict, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# following code: scrape each player's STATS info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_search = re.compile(r\"(\\d+)$\")\n",
    "id_search = re.compile(r\"\\$\\.getJSON\\(\\\"/services/responsive-roster-bio\\.ashx\\\", {.*?player_id: (\\d+) }\")\n",
    "#group id number \n",
    "\n",
    "id_numbers = [] #use for debug\n",
    "\n",
    "for key,rec in record_dict.items():\n",
    "    ################################\n",
    "    ## Deal with stats\n",
    "    cur_href = rec[\"href\"]   #cur refers to current\n",
    "\n",
    "    cur_resp = requests.get(cur_href, headers=headers)\n",
    "    cur_body = cur_resp.content.decode(\"utf-8\")\n",
    "\n",
    "    cur_playernum = rec[\"number\"]\n",
    "    \n",
    "    cur_playerid = id_search.search(cur_body).group(1)\n",
    "    id_numbers.append(cur_playerid) #put the newly found playerid to the list \"id_numbers\"\n",
    "\n",
    "    cur_rp = rp_search.search(cur_href).group(1) #rp refers to rp id\n",
    "    cur_stat_url = 'http://goheels.com/services/responsive-roster-bio.ashx?type=stats&rp_id={}&path=mbball&year=2017&player_id={}'.format(cur_rp, cur_playerid)\n",
    "\n",
    "    stat_resp = requests.get(cur_stat_url,headers=headers)\n",
    "    \n",
    "    stat_content =  stat_resp.content.decode(\"utf-8\")\n",
    "\n",
    "    stat_json = json.loads(stat_content) #stat_json is a dictionary\n",
    "    #stat_content is a string in json format, so needs to load string json\n",
    "    \n",
    "    cur_stat_html = stat_json[\"current_stats\"]\n",
    "    #current_stats is a key named by the website author, key to html string\n",
    "\n",
    "    ## now we're organizing those stats and categorize them, saving them to a csv\n",
    "\n",
    "    if cur_playerid=='0':\n",
    "        continue\n",
    "        #this is for the special person who doesn't have any stat, his id is 0\n",
    "\n",
    "    attribute_list = []  # make a list of all the category names\n",
    "    sel_stat = scrapy.Selector(text=cur_stat_html).css(\"table\")  # get all information\n",
    "    stat_attributes = sel_stat.css(\"thead tr th\")\n",
    "    for attr in stat_attributes:\n",
    "        attribute_list.append(attr.xpath(\"string()\").extract()[0])\n",
    "\n",
    "    f = open(\"current_stats_of_{}.csv\".format(cur_playernum),'w+') # new a csv and open it\n",
    "    stat_writer = csv.writer(f)\n",
    "    stat_writer.writerow(attribute_list)  #write category names into 1st row of the csv\n",
    "\n",
    "    stat_rows = sel_stat.css(\"tbody tr\")\n",
    "    for stat_row in stat_rows:\n",
    "        cur_row=[]\n",
    "        cur_row.append(stat_row.css(\"td:nth-child(1)\").xpath(\"string()\").extract()[0]) \n",
    "        #put the dates to the list\n",
    "        \n",
    "        cur_row.append(stat_row.css(\"th\").xpath(\"string()\").extract()[0])\n",
    "        #put the name to the list\n",
    "        \n",
    "        for i in stat_row.xpath('td[@class=\"text-center\"]'):\n",
    "            cur_row.append(i.xpath(\"string()\").extract()[0])\n",
    "            #put other stats to the list\n",
    "        stat_writer.writerow(cur_row)\n",
    "        #write list to the csv file\n",
    "    \n",
    "\n",
    "    f.close()   # close the csv\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ################################\n",
    "  #so we get a json file includes all the basic info (scraped by the first part of the code)\n",
    " # and several csv file, each includes a player's STATs (scraped by the second part of the code)\n",
    "    #and we can clean them in panda \n",
    "    # WoW!!!!!! XD DONE!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
